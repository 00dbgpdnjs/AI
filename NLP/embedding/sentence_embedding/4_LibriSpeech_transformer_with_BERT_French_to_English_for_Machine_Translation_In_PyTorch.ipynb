{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a22a4e-5adc-4525-9b01-8c5abbfc81b7",
   "metadata": {},
   "source": [
    "#### Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "706ef8ab-96ff-4f4b-8ba8-fa961e235a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchtext==0.6.0 --quiet\n",
    "# !pip install nltk\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9298749b-ab65-4199-9627-60f3c4c92211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import random\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from pprint import pprint\n",
    "\n",
    "# Seeding for reproducible results everytime\n",
    "SEED = 777\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "98495466-3b88-4b7d-ba29-fa173d0082cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy_german = spacy.load(\"fr_core_news_sm\")\n",
    "# spacy_english = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f809f50e-3155-4d86-8d5a-490751a0cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_german(text):\n",
    "#   return [token.text for token in spacy_german.tokenizer(text)]\n",
    "\n",
    "# def tokenize_english(text):\n",
    "#   return [token.text for token in spacy_english.tokenizer(text)]\n",
    "\n",
    "# ### Sample Run ###\n",
    "# sample_text = \"I love machine learning\"\n",
    "# print(tokenize_english(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6bf8413d-0c0b-421e-8c0a-db45ab8585c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/data/hwyu/data/libri/'\n",
    "\n",
    "train_en_path = filepath+\"train/train.en\"\n",
    "train_de_path = filepath+\"train/train_gtranslate.fr\" \n",
    "\n",
    "train_oth_en_path = filepath+\"train/other.en\"\n",
    "train_oth_de_path = filepath+\"train/other_gtranslate.fr\" \n",
    "\n",
    "test_eng_path = filepath+\"test/test.en\"\n",
    "test_de_path = filepath+\"test/test_gtranslate.fr\"\n",
    "\n",
    "test_dev_eng_path = filepath+\"test/dev.en\"\n",
    "test_dev_de_path = filepath+\"test/dev_gtranslate.fr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a538b4d3-16c9-4c72-bdd7-d94e0500c326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29000\n",
      "['ADIEU VALENTINE ADIEU', 'PROVE IT DANGLARS', 'SAID FRANZ', 'SAID FRANZ', 'FERNAND MONDEGO', 'AND THE CORRIDOR', 'FOR ANDREA RONDOLO', 'FOR ANDREA RONDOLO', 'SAID FERNAND', 'SAID ANDREA']\n"
     ]
    }
   ],
   "source": [
    "end_line = 100000  # 끝 라인 (포함하지 않음)\n",
    "\n",
    "train_en_sub_raw = []  # 추출한 데이터를 저장할 리스트\n",
    "\n",
    "with open(train_en_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for i, line in enumerate(file):\n",
    "        train_en_sub_raw.append(line.strip())\n",
    "        if i + 1 >= end_line:\n",
    "            break\n",
    "\n",
    "# with open(train_oth_en_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#     for i, line in enumerate(file):\n",
    "#         train_en_sub_raw.append(line.strip())\n",
    "#         if i + 1 >= end_line:\n",
    "#             break\n",
    "            \n",
    "limit_data_len = 29000\n",
    "train_en_sub_raw = train_en_sub_raw[:limit_data_len]\n",
    "# 데이터 확인\n",
    "print(len(train_en_sub_raw))\n",
    "print(train_en_sub_raw[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0157fa42-b6d5-4c03-99a4-b152911bc4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29000\n",
      "['\"Adieu, Valentine, adieux!', 'Prouve, Danglars.', 'Dit Franz.', 'Dit Franz.', '\"\" Fernand Mondego.', '\"\" Et le couloir?', '\"\" Pour Andrea Rondolo?', '\"\" Pour Andrea Rondolo?', '\"A déclaré Fernand.', '\"Dit Andrea.']\n"
     ]
    }
   ],
   "source": [
    "train_fr_sub_raw = []\n",
    "\n",
    "with open(train_de_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for i, line in enumerate(file):\n",
    "        train_fr_sub_raw.append(line.strip())\n",
    "        if i + 1 >= end_line:\n",
    "            break\n",
    "\n",
    "# with open(train_oth_de_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#     for i, line in enumerate(file):\n",
    "#         train_fr_sub_raw.append(line.strip())\n",
    "#         if i + 1 >= end_line:\n",
    "#             break\n",
    "train_fr_sub_raw = train_fr_sub_raw[:limit_data_len]\n",
    "# 데이터 확인\n",
    "print(len(train_fr_sub_raw))\n",
    "print(train_fr_sub_raw[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "20706d31-3515-43a6-9f5f-53d7e0ac9586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IN ANOTHER THE GROUND WAS CUMBERED WITH RUSTY IRON MONSTERS OF STEAM BOILERS WHEELS CRANKS PIPES FURNACES PADDLES ANCHORS DIVING BELLS WINDMILL SAILS AND I KNOW NOT WHAT STRANGE OBJECTS ACCUMULATED BY SOME SPECULATOR AND GROVELLING IN THE DUST UNDERNEATH WHICH HAVING SUNK INTO THE SOIL OF THEIR OWN WEIGHT IN WET WEATHER THEY HAD THE APPEARANCE OF VAINLY TRYING TO HIDE THEMSELVES\\n', 'THE CLASH AND GLARE OF SUNDRY FIERY WORKS UPON THE RIVER SIDE AROSE BY NIGHT TO DISTURB EVERYTHING EXCEPT THE HEAVY AND UNBROKEN SMOKE THAT POURED OUT OF THEIR CHIMNEYS\\n']\n",
      "[\"Dans un autre, le terrain était encombré de monstres en fer rouillé de chaudières à vapeur, de roues, de manivelles, de tuyaux, de fours, de pagaies, d'ancrages, de cloches, de voiliers, et je ne sais pas quels objets étranges, accumulés par un spéculateur, et Se creusant dans la poussière, sous laquelle - s'étant enfoncée dans le sol de leur propre poids par temps humide - ils avaient l'apparence d'essayer vainement de se cacher.\\n\", \"Le choc et l'éblouissement de divers travaux de feu sur le côté de la rivière, se sont produits de nuit pour déranger tout sauf la fumée lourde et ininterrompue qui a répandu leurs cheminées.\\n\"]\n",
      "2048\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "with open(test_eng_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    test_en_raw = file.readlines()\n",
    "    \n",
    "with open(test_de_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    test_fr_raw = file.readlines()\n",
    "\n",
    "with open(test_dev_eng_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    test_dev_en_raw = file.readlines()\n",
    "    \n",
    "with open(test_dev_de_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    test_dev_fr_raw = file.readlines()\n",
    "\n",
    "print(test_en_raw[:2])\n",
    "print(test_fr_raw[:2])\n",
    "\n",
    "print(len(test_en_raw))\n",
    "print(len(test_fr_raw))\n",
    "# test_en_raw += test_dev_en_raw\n",
    "# test_fr_raw += test_dev_fr_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a2b4ffd8-f8ec-49e0-806b-9d96898c771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def find_sentences_with_numbers(filename):\n",
    "# def find_sentences_with_numbers(lines):\n",
    "#     # with open(filename, 'r') as file:\n",
    "#         # lines = file.readlines()\n",
    "#         indices = []\n",
    "#         for i, line in enumerate(lines):\n",
    "#             # @ any(): 제너레이터 표현식을 통해 반복 가능한 객체를 받고, 그 객체의 요소 중 하나라도 True로 평가되는 경우 True를 반환\n",
    "#             if any(char.isdigit() for char in line):\n",
    "#                 print(f\"Line {i}: {line}\")\n",
    "#                 indices.append(i)\n",
    "#         return indices\n",
    "\n",
    "# # 파일명을 지정하여 함수를 호출합니다.\n",
    "# # find_sentences_with_numbers(\"your_text_file.txt\")\n",
    "# # indices_fr = find_sentences_with_numbers(train_fr_sub_raw) # 734 \n",
    "# indices_en = find_sentences_with_numbers(train_en_sub_raw) # 20\n",
    "# # indices_en_test = find_sentences_with_numbers(test_en_raw) # 0\n",
    "# # indices_en_test = find_sentences_with_numbers(test_fr_raw) # 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6b067fda-52ce-4437-a468-f0384e640fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일에 포함된 모든 문자: {'u', 'n', 'm', 'q', 'w', '\"', 's', '-', 'o', 'l', '6', '$', \"'\", ',', 'b', '5', ' ', '4', 'h', '_', 'j', ';', 'c', 'e', 't', '?', '3', 'p', 'i', 'a', 'r', 'g', '2', '9', '.', ')', '*', '0', '7', 'x', '(', ']', ':', '8', 'f', 'z', 'v', '!', 'd', '[', '1', 'y', '&', 'k'}\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return normalize('NFD', s).encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "def normalizeString(s):\n",
    "    return unicodeToAscii(s.lower())\n",
    "\n",
    "def normalizeStrings(lines):\n",
    "    return [normalizeString(s) for s in lines]\n",
    "\n",
    "def check_characters_in_file(lines):\n",
    "\n",
    "    # 각 문장에 포함된 모든 문자를 저장할 빈 세트를 생성\n",
    "    all_characters = set()\n",
    "\n",
    "    # 각 문장을 반복하면서 문자를 세트에 추가\n",
    "    for line in lines:\n",
    "        # 개행 문자 및 불필요한 공백 제거\n",
    "        line = line.strip()\n",
    "        # 문장에 포함된 모든 문자를 세트에 추가\n",
    "        all_characters.update(set(line))\n",
    "\n",
    "    return all_characters\n",
    "# characters_in_file = check_characters_in_file(normalizeStrings(test_fr_raw))\n",
    "characters_in_file = check_characters_in_file(normalizeStrings(train_fr_sub_raw)) # other_gtranslatefr : 모든 알파벳과 숫자, ')}_%+?&:\"/-{[(.,;*!$[, 스페이 \n",
    "print(\"파일에 포함된 모든 문자:\", characters_in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7c40125f-98f9-466b-b726-0d23eec44713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일에 포함된 모든 문자: {'W', 'Z', 'V', '3', 'Y', 'X', 'K', '2', 'O', '9', 'I', 'F', 'P', 'L', 'M', 'R', 'J', 'T', 'H', 'S', 'D', 'A', '0', '6', 'Q', '7', 'N', '8', 'U', '5', 'E', 'B', ' ', '4', '1', 'G', 'C'}\n"
     ]
    }
   ],
   "source": [
    "def check_characters_in_file(file_path):\n",
    "    # 파일을 열고 모든 내용을 읽어들임\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # 각 문장에 포함된 모든 문자를 저장할 빈 세트를 생성\n",
    "    all_characters = set()\n",
    "\n",
    "    # 각 문장을 반복하면서 문자를 세트에 추가\n",
    "    for line in lines:\n",
    "        # 개행 문자 및 불필요한 공백 제거\n",
    "        line = line.strip()\n",
    "        # 문장에 포함된 모든 문자를 세트에 추가\n",
    "        all_characters.update(set(line))\n",
    "\n",
    "    return all_characters\n",
    "\n",
    "# 파일에서 사용된 모든 문자 확인\n",
    "# characters_in_file = check_characters_in_file(test_eng_path) # 알파벳(모두)과 스페이스 밖에 없음 \n",
    "# characters_in_file = check_characters_in_file(test_de_path) # 숫자는 7, 9 없음 / 스페이스랑 * ) . ; : ! ? $ - \" , ' (\n",
    "\n",
    "# train.en 은 작은 따옴표 없애서 dont, thats 이런 식으로 돼있고 other.en은 작은 따옴표 있어서 don't, that's 이렇게 돼있음(thats도 있긴험)\n",
    "characters_in_file = check_characters_in_file(train_en_path) # 알파벳(모두), 숫자(모두), 스페이스\n",
    "# characters_in_file = check_characters_in_file(train_de_path) # 알파벳(모두), 숫자(모두), 스페이스, * [ ) . ; : ! ? $ ] - \" , & ' , _ \n",
    "print(\"파일에 포함된 모든 문자:\", characters_in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "479cd556-e3a5-4590-96cb-bf93409b8129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puis enfermant le reçu de monte cristos dans un petit livre de poche, il ajouta que oui, à 12 heures, je serai loin, puis il double verrouillé sa porte vide tous ses tiroirs recueillis environ cinquante mille francs en billets de banque ont brûlé plusieurs papiers laissés à d'autres exposés à la vue1876\n",
      "\n",
      "THEN ENCLOSING MONTE CRISTOS RECEIPT IN A LITTLE POCKET BOOK HE ADDED YES COME AT TWELVE OCLOCK I SHALL THEN BE FAR AWAY THEN HE DOUBLE LOCKED HIS DOOR EMPTIED ALL HIS DRAWERS COLLECTED ABOUT FIFTY THOUSAND FRANCS IN BANK NOTES BURNED SEVERAL PAPERS LEFT OTHERS EXPOSED TO VIEW1876\n"
     ]
    }
   ],
   "source": [
    "# print(train_fr_sub_raw[550])\n",
    "# print()\n",
    "# print(train_fr_g_sub_raw[550]) # en과 동일\n",
    "# print()\n",
    "# print(train_en_sub_raw[550]) # train_fr_sub_raw[550] 의 콜론 이후는 번역x\n",
    "\n",
    "# 의미는 같은데 fr의 ; : 가 en에 없음 \n",
    "# print(train_fr_sub_raw[616])\n",
    "# print()\n",
    "# print(train_fr_g_sub_raw[616])\n",
    "# print()\n",
    "# print(train_en_sub_raw[616])\n",
    "\n",
    "# print(train_fr_sub_raw[702])\n",
    "# print(train_en_sub_raw[702]) # fr의 숫자를 영어로 씀 \n",
    "\n",
    "# ?? 숫자 뭐지 \n",
    "# print(train_fr_sub_raw[3135]) # « Six cent mille?\n",
    "# print()\n",
    "# print(train_fr_g_sub_raw[3135]) # ~~~ 700 000 000 000\n",
    "# print()\n",
    "# print(train_en_sub_raw[3135]) # SIX HUNDRED THOUSAND700000800000\n",
    "\n",
    "# print(train_fr_sub_raw[11486])\n",
    "# print()\n",
    "# print(train_fr_g_sub_raw[11486]) # en 처럼 3651364\n",
    "# print()\n",
    "# print(train_en_sub_raw[11486]) # HIM 옆에 의미없는 3651364 가 붙어있음  \n",
    "\n",
    "print(train_fr_sub_raw[4191]) # 이것만 문장 더 있고 g trans가 맞음\n",
    "print()\n",
    "# print(train_fr_g_sub_raw[4191])\n",
    "# print()\n",
    "print(train_en_sub_raw[4191])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b952f578-ac68-4482-9228-6fb6b584b808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, Beauchamp, Beauchamp, comment puis-je aborder le mien?\n",
      "oh beauchamp beauchamp comment puis je aborder le mien\n",
      "Mais, après m'avoir péché, peut-être plus profondément que d'autres, je ne me reposerai jamais avant d'avoir déchiré les semblables de mes semblables et j'ai découvert leurs faiblesses. Je les ai toujours trouvés; Et plus encore, je le répète avec joie, avec triomphe, j'ai toujours trouvé une preuve de perversité humaine ou d'erreur.\n",
      "mais apres m avoir peche peut etre plus profondement que d autres je ne me reposerai jamais avant d avoir dechire les semblables de mes semblables et j ai decouvert leurs faiblesses je les ai toujours trouves et plus encore je le repete avec joie avec triomphe j ai toujours trouve une preuve de perversite humaine ou d erreur\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "from unicodedata import normalize\n",
    "import re\n",
    "\n",
    "# def unicodeToAscii(s):\n",
    "#     # return ''.join( # 악센트 있는 문자 통째로 제거\n",
    "#     #     c for c in unicodedata.normalize('NFD', s)\n",
    "#     #     if unicodedata.category(c) != 'Mn'\n",
    "#     # )\n",
    "#     # 악센트만 제거\n",
    "#     return normalize('NFD', s).encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "def normalizeString(s):\n",
    "    # s = unicodeToAscii(s.lower().strip())\n",
    "    # s = unicodeToAscii(s)\n",
    "    s = unicodeToAscii(s.lower()) # 소문자 변환안하면 대문자 기준으로 토큰화되서 단어 집합 개수가 500개 정도 밖에 안나옴. 소문자 변환하면 적절하게 8000개 정도 나옴\n",
    "    # s = re.sub(r\"([.!?\\\"])\", r\" \\1\", s) # 마침표, 느낌표, 물음표, 따옴표 앞에 공백을 추가\n",
    "    # s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s) # G 영문 알파벳과 마침표(.), 느낌표(!), 물음표(?)를 제외한 모든 문자를 공백으로 대체/ +: 해당 패턴이 한 번 이상 반복\n",
    "    s = re.sub(r\"[^a-zA-Z]+\", r\" \", s) # 이 코드 실행 후 strip() 안하면 문장 앞뒤 제거됐을 때 공백생김 \n",
    "    return s.strip()\n",
    "\n",
    "print(train_fr_sub_raw[2222]) \n",
    "print(normalizeString(train_fr_sub_raw[2222]))\n",
    "\n",
    "print(train_fr_sub_raw[3332]) \n",
    "print(normalizeString(train_fr_sub_raw[3332]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "91a26d74-445e-4b81-af9c-86bc7ab5846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeStrings(lines):\n",
    "    return [normalizeString(s) for s in lines]\n",
    "    \n",
    "train_fr_sub = normalizeStrings(train_fr_sub_raw)\n",
    "train_en_sub = normalizeStrings(train_en_sub_raw)\n",
    "test_fr = normalizeStrings(test_fr_raw)\n",
    "test_en = normalizeStrings(test_en_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "87e15125-1d04-42f3-978b-4ecb4f838bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['le celebre cucumetto poursuivi dans les abruzzes chasse du royaume de naples ou il avait mene une guerre reguliere avait traverse le garigliano comme manfred et s etait refugie sur les rives de l amasine entre sonnino et juperno', 'vous connaissez les environs de paris alors', 'vous connaissez les environs de paris alors', 'franz prit la lampe et entra dans la grotte souterraine suivie de gaetano', 'gaetano ne se trompait pas']\n",
      "['\"Le célèbre Cucumetto, poursuivi dans les Abruzzes, chassé du royaume de Naples, où il avait mené une guerre régulière, avait traversé le Garigliano, comme Manfred, et s\\'était réfugié sur les rives de l\\'Amasine entre Sonnino et Juperno.', '\"\" Vous connaissez les environs de Paris, alors?', '\"\" Vous connaissez les environs de Paris, alors?', 'Franz prit la lampe et entra dans la grotte souterraine, suivie de Gaetano.', 'Gaetano ne se trompait pas.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_fr_sub[100:105])\n",
    "print(train_fr_sub_raw[100:105])\n",
    "print()\n",
    "\n",
    "# print(train_en_sub[1000:1005])\n",
    "# print(train_en_sub_raw[1000:1005])\n",
    "# print()\n",
    "\n",
    "# print(test_fr[100:105])\n",
    "# print(test_fr_raw[100:105])\n",
    "# print()\n",
    "\n",
    "# print(test_en[100:105])\n",
    "# print(test_en_raw[100:105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0198cd92-419e-45ff-8211-157187c5bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # G default: (Field 클래스는 텍스트 데이터를 정수 시퀀스로 변환하고,) 텐서로 만들 때 배치 차원을 두 번째 차원으로 배치 (즉, (시퀀스 길이, 배치 크기))\n",
    "# german = Field(tokenize=tokenize_german,\n",
    "#                lower=True,\n",
    "#                init_token=\"<sos>\",\n",
    "#                eos_token=\"<eos>\", \n",
    "#                batch_first=True)\n",
    "\n",
    "# english = Field(tokenize=tokenize_english,\n",
    "#                lower=True,\n",
    "#                init_token=\"<sos>\",\n",
    "#                eos_token=\"<eos>\", \n",
    "#                batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "222b03d8-7c03-4cb8-b84c-f456d1dbfac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "버트 모델의 CLS 토큰 ID: 101\n",
      "버트 모델의 SEP 토큰 ID: 102\n",
      "버트 모델의 MASK 토큰 ID: 103\n",
      "버트 모델의 PAD 토큰 ID: 0\n",
      "torchtext의 CLS 토큰 ID: 101\n",
      "torchtext의 SEP 토큰 ID: 102\n",
      "torchtext의 MASK 토큰 ID: 100\n",
      "torchtext의 PAD 토큰 ID: 0\n",
      "torchtext의 CLS 토큰 ID: 101\n",
      "torchtext의 SEP 토큰 ID: 102\n",
      "torchtext의 MASK 토큰 ID: 100\n",
      "torchtext의 PAD 토큰 ID: 0\n",
      "단어 'hello'의 토큰화 결과: ['hell', '##o']\n",
      "단어 'hello'의 버트 모델의 토큰 ID: [61694, 10133]\n",
      "단어 'hello'의 토큰 ID: 61694\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Field' object has no attribute 'vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[241], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m단어 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m의 버트 모델의 토큰 ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, word_ids)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m단어 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m의 토큰 ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, word_ids[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m단어 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m의 torchtext의 토큰 ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43menglish\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[38;5;241m.\u001b[39mstoi[word_tokens[\u001b[38;5;241m0\u001b[39m]])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Field' object has no attribute 'vocab'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "# BERT 모델과 토크나이저 로드\n",
    "bert_model_name = 'bert-base-multilingual-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "# TorchText를 사용하여 데이터 필드(Field) 정의\n",
    "# G pad_token (default=\"<pad>\")\n",
    "german = Field(tokenize=tokenizer.tokenize, lower=True, init_token=\"[CLS]\", eos_token=\"[SEP]\", pad_token=\"[PAD]\", batch_first=True)\n",
    "english = Field(tokenize=tokenizer.tokenize, lower=True, init_token=\"[CLS]\", eos_token=\"[SEP]\", pad_token=\"[PAD]\", batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98bf53a-9b2e-4dff-92cd-e7b30d0f4486",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is an example sentence.\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65757363-45df-4a71-909d-b813fabaa5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Dataset, Example\n",
    "\n",
    "def create_dataset(text_list, field_name, field_obj):\n",
    "    # G Example.fromlist(data_list, fields) : field 정의에 따라 데이터를 적절히 처리하고 Example 객체를 생성\n",
    "    #   data_list의 순서는 필드 정의에서 지정한 순서와 일치해야 합니다.\n",
    "    examples = [Example.fromlist([text], [(field_name, field_obj)]) for text in text_list]\n",
    "    return Dataset(examples, fields=[(field_name, field_obj)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8686154-9e3d-46c4-b999-79fa5701daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import FastText, GloVe\n",
    "\n",
    "flag_pretrained_emb = False \n",
    "\n",
    "train_data = create_dataset(train_fr_sub, 'src', german)\n",
    "\n",
    "train_data.fields['trg'] = english\n",
    "train_en_data = create_dataset(train_en_sub, 'trg', english)\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    train_data[i].trg = train_en_data[i].trg\n",
    "\n",
    "test_data = create_dataset(test_fr, 'src', german)\n",
    "\n",
    "test_data.fields['trg'] = english\n",
    "test_en_path = create_dataset(test_en, 'trg', english)\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    test_data[i].trg = test_en_path[i].trg\n",
    "\n",
    "max_vocab_size = 10000 # 12000\n",
    "if flag_pretrained_emb :\n",
    "    print(\"loading fr_pretrained_emb. . .\")\n",
    "    fr_pretrained_emb = GloVe(name='6B', dim=300, cache='/data/hwyu/1_seq2seq/cache_dir_fr') # 텍스트가 6억 단어로 훈련된 것 / 50, 100, 200, 300\n",
    "    print(\"loading en_pretrained_emb. . .\")\n",
    "    en_pretrained_emb = GloVe(name='6B', dim=300, cache='/data/hwyu/1_seq2seq/cache_dir_en')\n",
    "    \n",
    "    # print(\"loading fr_fasttext. . .\")\n",
    "    # fr_pretrained_emb = torch.load('/data/hwyu/1_seq2seq/fr_fasttext_dim300.pt')\n",
    "    # print(\"loading en_fasttext. . .\")\n",
    "    # en_pretrained_emb = torch.load('/data/hwyu/1_seq2seq/en_fasttext_dim300.pt')\n",
    "    \n",
    "    print(\"load 완료\\n\")\n",
    "\n",
    "    german.build_vocab(train_data, max_size=max_vocab_size, min_freq=3, vectors=fr_pretrained_emb)\n",
    "    english.build_vocab(train_data, max_size=max_vocab_size, min_freq=3, vectors=en_pretrained_emb)\n",
    "else :\n",
    "    german.build_vocab(train_data, max_size=max_vocab_size, min_freq=3)\n",
    "    english.build_vocab(train_data, max_size=max_vocab_size, min_freq=3)\n",
    "\n",
    "print(english.vocab.freqs.most_common(10))\n",
    "print(german.vocab.freqs.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df57cc-6d22-459f-863b-8d83f60cd3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_pretrained_emb :\n",
    "    fr_pretrained_emb.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1e03a5-af40-464c-a736-384af89d7f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_data:\n",
    "    print(f\"txt 파일 : {train_en_sub[0]}\")\n",
    "    print(data.trg) # ?? 왜 공백 \n",
    "    print(f\"txt 파일 : {train_fr_sub[0]}\")\n",
    "    print(data.src) \n",
    "    # print(\"German - \",*data.src, \" Length - \", len(data.src))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0a85e-2b4e-400a-9498-9dca0cbfe109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(english.vocab.stoi)  # 단어를 정수로 매핑한 딕셔너리 출력\n",
    "print(list(german.vocab.stoi.items())[:10])\n",
    "print(list(german.vocab.stoi.items())[5000:5010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305d82a-0227-45dd-a4c4-83afd1a0c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"단어 사전의 크기 확인:\")\n",
    "print(f\"Unique tokens in source (de) vocabulary: {len(german.vocab)}\") # max : 16926 (g trans)\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(english.vocab)}\") # max : 16197\n",
    "\n",
    "if flag_pretrained_emb :\n",
    "    print(\"\\n임베딩 벡터 확인:\")\n",
    "    print(\"German Embedding Shape:\", german.vocab.vectors.shape)\n",
    "    print(\"English Embedding Shape:\", english.vocab.vectors.shape)\n",
    "    \n",
    "    print(\"\\n임베딩 벡터 값 확인:\")\n",
    "    print(\"German Embedding Vectors:\")\n",
    "    print(german.vocab.vectors)\n",
    "    print(\"English Embedding Vectors:\")\n",
    "    print(english.vocab.vectors)\n",
    "    \n",
    "    # G 특별 토큰들에 대한 임베딩은 훈련되지 않습니다. \n",
    "    #  따라서 초기화 단계에서는 이러한 토큰들의 임베딩은 보통 0으로 설정됩니다.\n",
    "    # print(torch.all(english.vocab.vectors[0] == english.vocab.vectors[1]))\n",
    "    # print(torch.all(english.vocab.vectors[1] == english.vocab.vectors[2]))\n",
    "    # print(torch.all(english.vocab.vectors[2] == english.vocab.vectors[3]))\n",
    "    # print(torch.all(english.vocab.vectors[3] == english.vocab.vectors[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f80d94-dd9a-4b04-afc3-c0ad4234866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_pretrained_emb :\n",
    "    def count_zero_rows(matrix):\n",
    "        count = 0\n",
    "        for row in matrix:\n",
    "            if all(element == 0 for element in row):\n",
    "                count += 1\n",
    "        return count\n",
    "    \n",
    "    # max_size=14000 : glove(fr:7926, en:416) / fasttext(fr:1316, en:120)\n",
    "    # max_size=10000 : glove(fr:5271, en:229)\n",
    "    print(\"0으로만 이루어진 행의 개수:\", count_zero_rows(german.vocab.vectors)) \n",
    "    print(\"0으로만 이루어진 행의 개수:\", count_zero_rows(english.vocab.vectors)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bb005e-ac38-4950-a7cf-514e63c3a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_pretrained_emb :\n",
    "    src_embedding = torch.nn.Embedding.from_pretrained(german.vocab.vectors)\n",
    "    trg_embedding = torch.nn.Embedding.from_pretrained(english.vocab.vectors) # freeze=True # 디폴트\n",
    "    print(src_embedding.weight.requires_grad)\n",
    "    \n",
    "    # 임베딩 레이어의 가중치 확인:\n",
    "    print(\"\\nGerman Embedding Layer Weights:\")\n",
    "    print(src_embedding.weight)\n",
    "    print(\"\\nEnglish Embedding Layer Weights:\")\n",
    "    print(trg_embedding.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2b58df-9ac9-4b4c-a959-640e11093bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(english.vocab) # G  속성과 메서드를 확인\n",
    "\n",
    "# G __dict__ : english.vocab 객체의 속성을 사전 형태로 반환\n",
    "print(english.vocab.__dict__.keys())\n",
    "print()\n",
    "e = list(english.vocab.__dict__.values())\n",
    "# print(e)\n",
    "\n",
    "# for i in e:\n",
    "#   print(i)\n",
    "'''\n",
    "len(e) # > 5\n",
    "e[0] # Counter ;각 단어의 빈도수 dict\n",
    "e[1] # 토큰 리스트\n",
    "e[2] # > 0 \n",
    "e[4] # 아무것도 출력 안됐음\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcf45c3-0bb2-4474-bdf1-a1ea35c5f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ 독일어는 왜 안하지 -> 영어가 출력이니까 영어만 원래 단어로 바꾸려는 듯\n",
    "word_2_idx = dict(e[3])\n",
    "idx_2_word = {} \n",
    "for k,v in word_2_idx.items():\n",
    "  idx_2_word[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2690b49f-0e8e-43e8-afcb-c4b247209f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(idx_2_word.items())[:10]) # @ (0, '0) 으로 출력되면 TabularDataset 셀에서 잘 못된 거일듯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1876173f-fbc6-4d59-9f4d-e919fe90e98a",
   "metadata": {},
   "source": [
    "#### Dataset sneek peek\n",
    "G 데이터셋의 내용을 간단하게 살펴보는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88fbedc-da45-4d06-b9fa-c15931ae20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G : TabularDataset train_data\n",
    "#  데이터를 행렬 형태로 표현\n",
    "#  각 열 : 필드(Field)로 정의되며, 데이터의 특성 나타냄 (ex. 텍스트, 레이블)\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "# print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")\n",
    "\n",
    "print(train_data[5].__dict__.keys())\n",
    "print(f\"txt 파일 : {train_fr_sub[5]}\")\n",
    "print(f\"txt 파일 : {train_en_sub[5]}\")\n",
    "# data 딕셔너리의 내용이 보기 좋게 출력\n",
    "pprint(train_data[5].__dict__.values()) # @나는 콤마 뒤는 잘림 .tok 파일은 다 자르나? 아니다  format='csv'로 해서 그런거였음  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221bfbc0-4da2-4642-8073-e788b062163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(train_data[36].__dict__.values())\n",
    "print(f\"txt 파일 : {train_fr_sub[36]}\")\n",
    "print(f\"txt 파일 : {train_en_sub[36]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8410813-eb23-4c7e-b868-49b5dbeb00c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data[113].__dict__.keys())\n",
    "pprint(test_data[113].__dict__.values())\n",
    "print(f\"txt 파일 : {test_fr[113]}\")\n",
    "print(f\"txt 파일 : {test_en[113]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af1bcdc-1ef2-4900-bc40-f2198acb55d3",
   "metadata": {},
   "source": [
    "- create batches of training, testing and validation data using iterators.\n",
    "- BucketIterator for effective padding of source and target sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92140290-aa5a-4d12-961f-c879d24bd597",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "BATCH_SIZE = 128 # 32, 128, 256\n",
    "\n",
    "train_iterator, test_iterator = BucketIterator.splits((train_data, test_data), \n",
    "                                                      batch_size = BATCH_SIZE, \n",
    "                                                      # sort_within_batch=True,\n",
    "                                                      sort_key=lambda x: len(x.src), # G 유사한 길이의 문장을 같은 배치로 묶기 위해\n",
    "                                                      device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ade604-337d-4294-93c5-a147fc8b87cd",
   "metadata": {},
   "source": [
    "#### Actual text data before tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df9d62-ed6d-44c5-9b3f-44b5acc87b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "max_len_eng = []\n",
    "max_len_ger = []\n",
    "for data in train_data:\n",
    "  max_len_ger.append(len(data.src))\n",
    "  max_len_eng.append(len(data.trg))\n",
    "  if count < 10 :\n",
    "    print(\"German - \",*data.src, \" Length - \", len(data.src))\n",
    "    print(\"English - \",*data.trg, \" Length - \", len(data.trg))\n",
    "    print()\n",
    "  count += 1\n",
    "\n",
    "print(\"Maximum Length of English sentence {} and German sentence {} in the dataset\".format(max(max_len_eng),max(max_len_ger)))\n",
    "print(\"Minimum Length of English sentence {} and German sentence {} in the dataset\".format(min(max_len_eng),min(max_len_ger)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c2446b-17d7-4465-93d3-7f77694530e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20000개 까지 중 가장 긴 : Voici ce que Fantine chantait:  _Nous achèterons de bien belles choses_ _En nous promenant le long des faubourgs._ _Les bleuets sont bleus, les roses sont roses,_ _Les bleuets sont bleus, j'aime mes amours._ _La vierge Marie auprès de mon poêle_ _Est venue hier en manteau brodé,_ _Et m'a dit:--Voici, caché sous mon voile,_ _Le petit qu'un jour tu m'as demandé._ _Courez à la ville, ayez de la toile,_ _Achetez du fil, achetez un dé._ _Nous achèterons de bien belles choses_ _En nous promenant le long des faubourgs._ _Bonne sainte Vierge, auprès de mon poêle_ _J'ai mis un berceau de rubans orné_ _Dieu me donnerait sa plus belle étoile,_ _J'aime mieux l'enfant que tu m'as donné._ --_Madame, que faire avec cette toile?_ --_Faites un trousseau pour mon nouveau-né._ _Les bleuets sont bleus, les roses sont roses,_ _Les bleuets sont bleus, j'aime mes amours._ --_Lavez cette toile._ --_Où?_--_Dans la rivière._ _Faites-en, sans rien gâter ni salir,_ _Une belle jupe avec sa brassière_ _Que je veux broder et de fleurs emplir._ --_L'enfant n'est plus là, madame, qu'en faire?_ --_Faites-en un drap pour m'ensevelir._ _Nous achèterons de bien belles choses_ _En nous promenant le long des faubourgs._ _Les bleuets sont bleus, les roses sont roses,_ _Les bleuets sont bleus, j'aime mes amours._  Cette chanson était une vieille romance de berceuse avec laquelle autrefois elle endormait sa petite Cosette, et qui ne s'était pas offerte à son esprit depuis cinq ans qu'elle n'avait plus son enfant.\n",
    "max_len_idx = max_len_ger.index(max(max_len_ger))\n",
    "print(f\"가장 긴 문장 인덱스 : {max_len_idx}\")\n",
    "# print(train_fr_sub_raw[max_len_idx])\n",
    "\n",
    "example = train_data[max_len_idx]\n",
    "# vars(example)[\"src\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f283291-51a4-4ac4-9609-f746d09e6029",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_idx = max_len_eng.index(max(max_len_eng))\n",
    "print(f\"가장 긴 문장 인덱스 : {max_len_idx}\")\n",
    "# print(train_en_sub_raw[max_len_idx])\n",
    "\n",
    "example = train_data[max_len_idx]\n",
    "example = train_data[max_len_idx]\n",
    "# vars(example)[\"trg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f444a5-8507-4e9c-8bf3-1753e2d2f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_longest_sentences_positions(sentences, n=5):\n",
    "#     sorted_positions = sorted(enumerate(sentences), key=lambda x: len(x[1]), reverse=True)[:n]\n",
    "#     return sorted_positions\n",
    "\n",
    "# # 가장 긴 10개의 문장의 위치를 가져옵니다.\n",
    "# longest_positions = get_longest_sentences_positions(train_fr_sub_raw, 10)\n",
    "\n",
    "# pos = []\n",
    "# for position, sentence in longest_positions:\n",
    "#     # print(f\"{position + 1}: {sentence}\")\n",
    "#     example = train_data[position]\n",
    "#     pos.append(len(vars(example)[\"src\"])) # src : [447, 307, 253, 246, 222, 189, 211, 201, 189, 188]\n",
    "# pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4dd1c3-b1b6-46bc-8eec-f217a3432e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len_idx = max_len_eng.index(min(max_len_eng))\n",
    "print(f\"가장 짧은 문장 인덱스 : {min_len_idx}\")\n",
    "print(train_en_sub_raw[min_len_idx])\n",
    "\n",
    "example = train_data[min_len_idx]\n",
    "vars(example)[\"trg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be6060-84ff-40f2-bf64-2e6c68979db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len_idx = max_len_ger.index(min(max_len_ger))\n",
    "print(f\"가장 짧은 문장 인덱스 : {min_len_idx}\")\n",
    "print(train_fr_sub_raw[min_len_idx]) # other_gtranslate[43220] > '' '' '' '' '' '' '' '' '' '' '' '' '' '' '\n",
    "print(f\"영어:{train_en_sub_raw[min_len_idx]}\") \n",
    "\n",
    "example = train_data[min_len_idx]\n",
    "vars(example)[\"src\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1eeb4a-c577-4a07-b054-9bba66b1384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if limit_data_len > 47248:\n",
    "    print(train_fr_sub_raw[46905])\n",
    "    print(train_en_sub_raw[46905])\n",
    "    print()\n",
    "    print(train_fr_sub_raw[47247])\n",
    "    print(train_en_sub_raw[47247])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccfb030-e8f2-4e48-acc7-d68e710a6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average lengths\n",
    "en_lengths = sum([len(sent) for sent in train_en_sub])/len(train_en_sub)\n",
    "de_lengths = sum([len(sent) for sent in train_fr_sub])/len(train_fr_sub)\n",
    "en_test_lengths = sum([len(sent) for sent in test_en])/len(test_en)\n",
    "de_test_lengths = sum([len(sent) for sent in test_fr])/len(test_fr)\n",
    "\n",
    "print(en_lengths, de_lengths)\n",
    "print(en_test_lengths, de_test_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821e18f-10e8-408b-a4a9-d974a74c4ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ en_lengths, de_lengths 둘 중 더 작은 값에 내림해서 두 배 한 정도\n",
    "# limited_seq_length = 20\n",
    "# limited_seq_length = int(min(en_lengths, de_lengths)) * 2\n",
    "# limited_seq_length = min(en_lengths, de_lengths)//5 * 5 * 2\n",
    "limited_seq_length = 250 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f3c521-f91e-4bef-a604-a06c53ac5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for data in train_iterator:\n",
    "#   if count < 1 :\n",
    "#     print(\"Shapes\", data.src.shape, data.trg.shape)\n",
    "#     print()\n",
    "#     print(\"German - \",*data.src, \" Length - \", len(data.src))\n",
    "#     print()\n",
    "#     print(\"English - \",*data.trg, \" Length - \", len(data.trg))\n",
    "#     temp_ger = data.src\n",
    "#     temp_eng = data.trg\n",
    "#     count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dccd582-bfe1-4a9f-b375-654ff59b7560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_eng_idx = (temp_eng).cpu().detach().numpy()\n",
    "# temp_ger_idx = (temp_ger).cpu().detach().numpy()\n",
    "# print(temp_ger_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f6e726-3fdc-4ff6-997f-4944664263a9",
   "metadata": {},
   "source": [
    "- I just experimented with a batch size of 32 and a sample target batch is shown below.\n",
    "- Each column corresponds to a sentence indexed into numbers and we have 32 such sentences in a single target batch and the number of rows corresponds to the maximum length of that sentence.\n",
    "- The table (Idx.csv) contains the numerical indices of the words, which is later fed into the word embedding and converted into dense representation for Seq2Seq processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8a4b20-5afd-4c68-93a0-83bfc575c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 배치에서 하나의 문장 정보 출력\n",
    "for i, batch in enumerate(train_iterator):\n",
    "    src = batch.src\n",
    "    trg = batch.trg\n",
    "    \n",
    "\n",
    "    print(f\"첫 번째 배치 크기: {src.shape}\") # 128개의 문장 중 가장 긴 문장의 길이가 35\n",
    "\n",
    "    # 현재 배치에 있는 하나의 문장에 포함된 정보 출력\n",
    "    for i in range(src.shape[1]): # 시퀀스 길이만큼 반복\n",
    "        print(f\"인덱스 {i}: {src[0][i].item()}\") # 여기에서는 [Seq_num, Seq_len] / > 1: 패팅 토큰\n",
    "\n",
    "    # 첫 번째 배치만 확인\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239bc168-dff0-4171-9183-f9ecc7c69e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_mask(src):\n",
    "    \"\"\"\n",
    "    주어진 입력 문장(src)에 대한 어텐션 마스크를 생성하는 함수\n",
    "\n",
    "    Args:\n",
    "        src (list): 패딩된 토큰을 포함한 배치 차원이 있는 입력 문장 리스트\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 생성된 어텐션 마스크 텐서\n",
    "    \"\"\"\n",
    "\n",
    "    SRC_PAD_IDX = german.vocab.stoi[german.pad_token]\n",
    "    TRG_PAD_IDX = english.vocab.stoi[english.pad_token]\n",
    "    assert SRC_PAD_IDX == TRG_PAD_IDX\n",
    "    \n",
    "    attention_mask = []\n",
    "    for seq in src:\n",
    "        seq_mask = [1 if token != SRC_PAD_IDX else 0 for token in seq]  # 패딩된 토큰에 대해 0으로 마스킹\n",
    "        attention_mask.append(seq_mask)\n",
    "    \n",
    "    # 리스트를 텐서로 변환하여 반환\n",
    "    return torch.tensor(attention_mask)\n",
    "\n",
    "# 함수 사용 예시\n",
    "src = [\n",
    "    [101, 2023, 2003, 1037, 2517, 2005, 0, 0, 1, 1],  # 첫 번째 문장\n",
    "    [101, 2054, 7922, 2003, 1037, 2829, 1012, 102, 0, 1],  # 두 번째 문장 (패딩)\n",
    "    # 더 많은 배치들...\n",
    "]\n",
    "\n",
    "attention_mask = create_attention_mask(src)\n",
    "print(attention_mask.shape)\n",
    "print(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f7a54b-a4cd-483a-a599-cb9131ff7f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_heads, dropout_ratio, device):\n",
    "        super().__init__()\n",
    "\n",
    "        # hidden_dim이 n_heads로 나누어 떨어지지 않으면 AssertionError를 발생시킴\n",
    "        # 이때 은닉 차원을 어텐션 헤드의 수로 나누어 떨어지게 하는 것은 헤드 간에 정보를 공유하고 연산을 병렬화하는 데 도움이 됨\n",
    "        assert hidden_dim % n_heads == 0\n",
    "\n",
    "        self.hidden_dim = hidden_dim # 임베딩 차원\n",
    "        self.n_heads = n_heads # 헤드(head)의 개수: 서로 다른 어텐션(attention) 컨셉의 수\n",
    "        self.head_dim = hidden_dim // n_heads # 각 헤드(head)에서의 임베딩 차원   / fc_q의 결과 디멘젼을 n_heads개로 쪼개서 사용\n",
    "\n",
    "        # 쿼리(Q)를 계산하기 위한 레이어 ;입력을 쿼리로 변환하기 위한 레이어\n",
    "        self.fc_q = nn.Linear(hidden_dim, hidden_dim) # Query 값에 적용될 FC 레이어\n",
    "        self.fc_k = nn.Linear(hidden_dim, hidden_dim) # Key 값에 적용될 FC 레이어\n",
    "        self.fc_v = nn.Linear(hidden_dim, hidden_dim) # Value 값에 적용될 FC 레이어\n",
    "\n",
    "        # 어텐션 메커니즘에서 사용되는 출력을 계산하기 위한 레이어\n",
    "        # : Q,K,V를 이용하여 어텐션을 계산한 후, 이를 조합하여 최종 출력을 생성\n",
    "          # 이 과정에서 self.fc_o는 어텐션 값을 변환하여 최종 출력을 계산\n",
    "        self.fc_o = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "\n",
    "    def forward(self, query, key, value, mask = None):\n",
    "\n",
    "        batch_size = query.shape[0]\n",
    "\n",
    "        # query: [batch_size, query_len, hidden_dim]   / query_len : 단어 개수\n",
    "        # key: [batch_size, key_len, hidden_dim]\n",
    "        # value: [batch_size, value_len, hidden_dim]\n",
    "\n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "\n",
    "        # Q: [batch_size, query_len, hidden_dim]\n",
    "        # K: [batch_size, key_len, hidden_dim]\n",
    "        # V: [batch_size, value_len, hidden_dim]\n",
    "\n",
    "        # hidden_dim → n_heads X head_dim 형태로 변형\n",
    "        # n_heads(h)개의 서로 다른 어텐션(attention) 컨셉을 학습하도록 유도\n",
    "        #   Q,K,V 결과 값을 h개로 나눠 사용 ;n_heads개 각각 마다 head_dim 만큼의 크기로 차원을 가지도록 만들어서 ;h개의 Q,K,V 만듦\n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        # ?? view(batch_size, self.n_heads, -1, self.head_dim) 이렇게 하면 permute 안해도 되지 않나\n",
    "        \n",
    "        # Q: [batch_size, n_heads, query_len, head_dim]\n",
    "        # K: [batch_size, n_heads, key_len, head_dim]\n",
    "        # V: [batch_size, n_heads, value_len, head_dim]\n",
    "\n",
    "        # Attention Energy 계산\n",
    "        # 각 head마다 Q,K 서로 곱하고 scale로 나눠서 energy 구함\n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "\n",
    "        # energy: [batch_size, n_heads, query_len, key_len]\n",
    "\n",
    "        # 마스크(mask)를 사용하는 경우\n",
    "        if mask is not None:\n",
    "            # 마스크(mask) 값이 0인 부분을 -1e10으로 채우기 -> softmax에 들어간 값이 거의 0%가 나오게\n",
    "            energy = energy.masked_fill(mask==0, -1e10)\n",
    "\n",
    "        # 어텐션(attention) 스코어 계산: 각 단어에 대한 확률 값\n",
    "        attention = torch.softmax(energy, dim=-1) # 마지막 차원을 따라 소프트맥스 연산 수행\n",
    "        # @ 각 행의 합이 1\n",
    "        \n",
    "        # attention: [batch_size, n_heads, query_len, key_len]\n",
    "\n",
    "        # 여기에서 Scaled Dot-Product Attention을 계산\n",
    "        # 위에서 softmax를 취해서 나온 attention 가중치 * V 해서 어텐션 밸값을 결과적으로 만들어줌\n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "\n",
    "        # x: [batch_size, n_heads, query_len, head_dim]\n",
    "\n",
    "        x = x.permute(0, 2, 1, 3).contiguous() # contiguous : 메모리 레이아웃을 연속적으로 만들어줌 -> 행렬 연산을 효율적으로 수행하기 위해\n",
    "        # ?? 왜 permute -> 다음 코드에서 n_heads, head_dim를 hidden_dim로 연결하기 위해\n",
    "        \n",
    "        # x: [batch_size, query_len, n_heads, head_dim]\n",
    "\n",
    "        x = x.view(batch_size, -1, self.hidden_dim) # ;일자로 쭉 늘어뜨림; concat\n",
    "\n",
    "        # x: [batch_size, query_len, hidden_dim]\n",
    "\n",
    "        x = self.fc_o(x)\n",
    "\n",
    "        # x: [batch_size, query_len, hidden_dim]\n",
    "\n",
    "        return x, attention # 나중에 시각화도 하려고 attention 스코어값도 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9d07a2-be1f-4a1a-806e-67ea5c157133",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, pf_dim, dropout_ratio):\n",
    "        super().__init__()\n",
    "\n",
    "        # hidden_dim -> hidden_dim : 입출력 차원 동일\n",
    "        self.fc_1 = nn.Linear(hidden_dim, pf_dim)\n",
    "        self.fc_2 = nn.Linear(pf_dim, hidden_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x: [batch_size, seq_len, hidden_dim]\n",
    "\n",
    "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
    "\n",
    "        # x: [batch_size, seq_len, pf_dim]\n",
    "\n",
    "        x = self.fc_2(x)\n",
    "\n",
    "        # x: [batch_size, seq_len, hidden_dim]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c1863-f69c-43cb-a256-a12573b3bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
    "        super().__init__()\n",
    "\n",
    "        # 4개의 실질적인 레이어가 들어있음 ;인코더가 이렇게 구성됨\n",
    "        # ?? nn.LayerNorm 하나만 정의하면 안되는가\n",
    "        #  G elementwise_affine=True가 기본값이므로, 감마와 베타를 학습할 수 있습니다.\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    # 하나의 임베딩이 복제되어 Query, Key, Value로 입력되는 방식\n",
    "    def forward(self, src, src_mask):\n",
    "\n",
    "        # src: [batch_size, src_len, hidden_dim]\n",
    "        # src_mask: [batch_size, src_len]\n",
    "\n",
    "        # self attention\n",
    "        # 필요한 경우 마스크(mask) 행렬을 이용하여 어텐션(attention)할 단어를 조절 가능\n",
    "        # 입력값 src이 q, k, v로 같은 값을 넣어줌\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
    "\n",
    "        # dropout, residual connection and layer norm\n",
    "        # 괄호가 residual connection\n",
    "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "\n",
    "        # src: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "        # position-wise feedforward\n",
    "        _src = self.positionwise_feedforward(src)\n",
    "\n",
    "        # dropout, residual and layer norm\n",
    "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
    "\n",
    "        # src: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f7fc57-42c7-46d4-9fb6-05ddae9e2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=512): # max_length: 버트의 입력 최대 길이가 512라서\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        # input_dim : 단어 개수 \n",
    "        # G Embedding : 입력값을 벡터 공간으로 매핑하기 위해 weight 매개변수를 사용\n",
    "          # input_dim: Embedding 계층에 입력될 값의 총 개수\n",
    "          # weight : input_dim x hidden_dim 크기의 행렬로, 각 입력값에 대응하는 벡터를 생성\n",
    "        # if flag_pretrained_emb :\n",
    "        #     self.tok_embedding = src_embedding\n",
    "        # else :\n",
    "        #     self.tok_embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        # G 입력 시퀀스의 위치 인덱스를 크기 hidden_dim의 밀집 벡터로 매핑\n",
    "          #  모델이 입력 시퀀스의 위치에 대한 의미 있는 표현을 학습\n",
    "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
    "        # 논문과 달리 위치 임베딩 학습 ;이미 정해져 있는 sin, cos 사용x\n",
    "\n",
    "        # n_layers 만큼 EncoderLayer 반복\n",
    "        self.layers = nn.ModuleList([EncoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "\n",
    "        # src: [batch_size, src_len]\n",
    "        # src_mask: [batch_size, src_len]\n",
    "\n",
    "        batch_size = src.shape[0] # 문장 개수 \n",
    "        src_len = src.shape[1]\n",
    "\n",
    "        # arange(0, src_len) 를 문장 마다 적용하도록 repeat()\n",
    "        # G unsqueeze : (src_len,) -> (1, src_len)  /반복되는 배치 차원을 추가하기 위해\n",
    "        # G repeat: 텐서를 복제하여 지정된 차원에 해당하는 수만큼 복제\n",
    "          # 행을 batch_size만큼 복제하여 배치 차원을 생성\n",
    "        # G batch에 대한 positional encoding을 만듦\n",
    "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "\n",
    "        # pos: [batch_size, src_len]\n",
    "\n",
    "        # print(src[0]) # tensor([   2,    7,  233,  ..., 4390,    3,  1,    1,   ...    1],\n",
    "        '''attention_mask 생성\n",
    "        # decoded_text = tokenizer.decode(src) # TypeError: int() argument must be a string, a bytes-like object or a real number, not 'list'\n",
    "        decoded_text = tokenizer.batch_decode(src)\n",
    "        # print(decoded_text.shape) # AttributeError: 'list' object has no attribute 'shape'\n",
    "        print(decoded_text[0]) # [unused2] [unused19] [unused28] [SEP] [unused25] 寝 သ [unused24] Ե [unused38] [unused19] [unused40] [unused58] E [unused6] [unused8] [unused3] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1]\n",
    "        # G는 return_special_tokens_mask=False이긴한데 사이트에서는 특별토큰도 출력되던데\n",
    "        attention_mask = tokenizer.batch_encode_plus(decoded_text, padding=True, return_attention_mask=True)['attention_mask']\n",
    "        # print(attention_mask.shape) # 불가\n",
    "        print(attention_mask[0])\n",
    "        '''\n",
    "\n",
    "        attention_mask = create_attention_mask(src)\n",
    "        print(attention_mask.shape) # torch.Size([128, 166])\n",
    "        # print(src[:2]) \n",
    "        # print(attention_mask[:2])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # G bert_model() :\n",
    "                # input_ids: BERT 모델의 입력으로 사용되는 토큰 ID 시퀀스 /  shape: (배치 크기, 시퀀스 길이)\n",
    "                # attention_mask: 기본값 None\n",
    "                # token_type_ids: 기본값 None ; 하나의 시퀀스로 간주 ;단일 문장 처리\n",
    "                # return_dict: 기본값 True  \n",
    "                    # False: 튜플의 형태로 반환되며, 반환된 튜플의 첫 번째 요소는 last_hidden_state이고 두 번째 요소는 pooler_output\n",
    "            # print(bert_model(input_ids=src.cpu()).shape) # AttributeError: 'BaseModelOutputWithPoolingAndCrossAttentions' object has no attribute 'shape'\n",
    "            # tok_embedding = bert_model(input_ids=src.cpu())[0]\n",
    "            tok_embedding = bert_model(input_ids=src.cpu(), attention_mask=attention_mask)[0]\n",
    "            # print(tok_embedding.shape) # [128, 82, 768]\n",
    "\n",
    "        # 소스 문장의 임베딩과 위치 임베딩을 더한 것을 실제 입력값으로 사용\n",
    "        src = self.dropout((tok_embedding.to(device) * self.scale) + self.pos_embedding(pos))\n",
    "\n",
    "        # src: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "        # 모든 인코더 레이어를 차례대로 거치면서 순전파(forward) 수행\n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "\n",
    "        # src: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "        return src # 마지막 레이어의 출력을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d23234d-d4eb-4ce5-9981-273ee576e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
    "        super().__init__()\n",
    "\n",
    "        # 총 6개 레이어 <- 디코더가 이렇게 구성됨. 이걸 여러번 중첩\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.enc_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
    "        self.encoder_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    # 인코더의 출력 값(enc_src)을 어텐션(attention)하는 구조\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "\n",
    "        # trg: [batch_size, trg_len, hidden_dim]\n",
    "        # enc_src: [batch_size, src_len, hidden_dim]\n",
    "        # trg_mask: [batch_size, trg_len] \n",
    "        # src_mask: [batch_size, src_len]\n",
    "        # mask 크기 잘 못 쓴 듯 : 두 코드 참고\n",
    "            # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
    "            # energy.masked_fill(mask==0, -1e10)\n",
    "\n",
    "        # 1. self attention\n",
    "        # 자기 자신에 대하여 어텐션(attention)\n",
    "        # 1~3rd : q,k,v는 모두 자기 자신(trg)을 넣어서 만듦\n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "\n",
    "        # 2. dropout, residual connection and layer norm\n",
    "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "\n",
    "        # trg: [batch_size, trg_len, hidden_dim]\n",
    "\n",
    "        # 3. encoder attention\n",
    "        # 디코더의 쿼리(Query)를 이용해 인코더를 어텐션(attention)\n",
    "        # 인코더 디코더 어텐션 수행 : 인코더에서 정보를 가져옴\n",
    "        # Q - trg : 디코드에 포함되어 있는 출력 단어들에 대한 정보\n",
    "        # K - enc_src : 인코더에서 가장 마지막 출력 값으로 나온 값\n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "\n",
    "        # dropout, residual connection and layer norm\n",
    "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "\n",
    "        # trg: [batch_size, trg_len, hidden_dim]\n",
    "\n",
    "        # positionwise feedforward\n",
    "        _trg = self.positionwise_feedforward(trg)\n",
    "\n",
    "        # dropout, residual and layer norm\n",
    "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "\n",
    "        # trg: [batch_size, trg_len, hidden_dim]\n",
    "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
    "\n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d6c00b-1e98-41b3-9cf6-7e91cc36c273",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        # output_dim : 단어 개수\n",
    "        # if flag_pretrained_emb :\n",
    "        #     self.tok_embedding = trg_embedding\n",
    "        # else :        \n",
    "        #     self.tok_embedding = nn.Embedding(output_dim, hidden_dim)\n",
    "        # max_length : seq len \n",
    "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
    "\n",
    "        self.layers = nn.ModuleList([DecoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
    "\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "\n",
    "        # trg: [batch_size, trg_len] /타겟 문장에 대한 정보\n",
    "        # enc_src: [batch_size, src_len, hidden_dim] /인코더 마지막 출력값\n",
    "        # trg_mask: [batch_size, trg_len]\n",
    "        # src_mask: [batch_size, src_len]\n",
    "\n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "\n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "\n",
    "        # pos: [batch_size, trg_len]\n",
    "\n",
    "        attention_mask = create_attention_mask(trg)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            tok_embeddings = bert_model(input_ids=trg.cpu(), attention_mask=attention_mask)[0]\n",
    "        \n",
    "        trg = self.dropout((tok_embeddings.to(device) * self.scale) + self.pos_embedding(pos))\n",
    "\n",
    "        # trg: [batch_size, trg_len, hidden_dim]\n",
    "\n",
    "        for layer in self.layers:\n",
    "            # 소스 마스크와 타겟 마스크 모두 사용\n",
    "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
    "\n",
    "        # trg: [batch_size, trg_len, hidden_dim]\n",
    "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
    "\n",
    "        # 출력을 위한 fc 거침\n",
    "        output = self.fc_out(trg)\n",
    "\n",
    "        # output: [batch_size, trg_len, output_dim]\n",
    "\n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a26dcec-7392-4f25-941b-08b9d6a5efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "\n",
    "    # 소스 문장의 <pad> 토큰에 대하여 마스크(mask) 값을 0으로 설정\n",
    "    def make_src_mask(self, src):\n",
    "\n",
    "        # src: [batch_size, src_len]\n",
    "\n",
    "        # G () : 패딩 토큰과 일치하지 않는 위치를 찾음\n",
    "        #   unsqueeze(2) : 브로드캐스팅(broadcasting) 연산을 수행할 수 있도록\n",
    "        #   src_mask : 패딩 토큰을 포함하지 않는 입력 시퀀스의 위치에는 True\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # src_mask: [batch_size, 1, 1, src_len]\n",
    "\n",
    "        return src_mask\n",
    "\n",
    "    # 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용\n",
    "    def make_trg_mask(self, trg):\n",
    "\n",
    "        # trg: [batch_size, trg_len]\n",
    "\n",
    "        # 1. 소스 문장과 동일하게 pad 마스킹  \n",
    "        \"\"\" (마스크 예시)\n",
    "        1 0 0 0 0\n",
    "        1 1 0 0 0\n",
    "        1 1 1 0 0\n",
    "        1 1 1 0 0\n",
    "        1 1 1 0 0\n",
    "        \"\"\"\n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # trg_pad_mask: [batch_size, 1, 1, trg_len]\n",
    "\n",
    "        trg_len = trg.shape[1]\n",
    "\n",
    "        # 2. 별도의 마스크 하나 더 만듦 : 앞쪽 단어만 볼 수 있게\n",
    "        \"\"\" (마스크 예시)\n",
    "        1 0 0 0 0\n",
    "        1 1 0 0 0\n",
    "        1 1 1 0 0\n",
    "        1 1 1 1 0\n",
    "        1 1 1 1 1\n",
    "        \"\"\"\n",
    "        # G .tril()은 행렬의 하삼각 부분을 반환. 모두 1로 채워진 행렬에 적용\n",
    "          # (trg_len, trg_len)은 정사각형 행렬을 생성하기 위해\n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
    "\n",
    "        # trg_sub_mask: [trg_len, trg_len]\n",
    "\n",
    "        # G 브로드캐스팅은\n",
    "          # 두 배열의 차원 수가 다르면 차원 수가 더 적은 배열의 형상이 더 많은 배열의 형상에 맞춰지도록 자동으로 확장\n",
    "          # 두 배열의 크기가 어느 한 차원에서 일치하지 않으면 크기가 1인 차원이 다른 배열의 크기에 맞추어 확장\n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "\n",
    "        # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
    "\n",
    "        return trg_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "\n",
    "        # src: [batch_size, src_len]\n",
    "        # trg: [batch_size, trg_len]\n",
    "\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "\n",
    "        # src_mask: [batch_size, 1, 1, src_len]\n",
    "        # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
    "\n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "\n",
    "        # enc_src: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "        # output : 번역 결과\n",
    "        # 디코더는 매번 enc_src(인코더의 출력값)을 어텐션\n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "\n",
    "        # output: [batch_size, trg_len, output_dim]\n",
    "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
    "\n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cbd188-b0c1-4d19-809a-f992c72098e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(german.vocab) # > len(german.vocab)\n",
    "OUTPUT_DIM = len(english.vocab)\n",
    "# HIDDEN_DIM = len(src_embedding.weight[1]) # 256\n",
    "HIDDEN_DIM = bert_model.config.hidden_size\n",
    "ENC_LAYERS = 3 # 6\n",
    "DEC_LAYERS = 3 # 6\n",
    "ENC_HEADS = 6 # 8\n",
    "DEC_HEADS = 6 # 8\n",
    "ENC_PF_DIM = 512 # 2048\n",
    "DEC_PF_DIM = 512 # 2048\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2631db-1cb1-44fd-a087-faf32eb0c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G SRC 텍스트 필드에서 pad_token 속성을 사용하여 패딩 토큰의 문자열을 가져온 다음, stoi (string to index) 속성을 사용하여 해당 문자열을 정수 인덱스로 변환\n",
    "SRC_PAD_IDX = german.vocab.stoi[german.pad_token]\n",
    "TRG_PAD_IDX = english.vocab.stoi[english.pad_token]\n",
    "\n",
    "# 인코더(encoder)와 디코더(decoder) 객체 선언\n",
    "enc = Encoder(INPUT_DIM, HIDDEN_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
    "dec = Decoder(OUTPUT_DIM, HIDDEN_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
    "\n",
    "# Transformer 객체 선언\n",
    "model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910fbfee-54eb-4b2e-9731-6debd34b2135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    # G numel() : 해당 텐서의 총 요소 수 반환\n",
    "    #   다차원 텐서의 경우 모든 차원의 크기를 곱한 값 반환\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d149d-7024-4eeb-b337-0f72dc212f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m): # m(모듈): 각 레이어\n",
    "    # G 차원이 1보다 작으면 해당 텐서가 벡터이며, 일반적으로 이러한 경우에는 Xavier 초기화를 적용x\n",
    "      # 가중치 텐서의 차원이 1보다 작은 경우는 보통 편향(bias)을 나타냅니다. 대부분의 PyTorch 레이어는 가중치와 편향을 함께 가지고 있습니다\n",
    "      # Xavier 초기화는 주로 가중치에 대해서만 적용되기 때문에 가중치 텐서의 차원이 1보다 작은 경우 Xavier 초기화를 적용하지 않는 것이 일반적\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        # G Xavier 초기화는 각 가중치를 평균이 0이고 분산이 2/(입력 개수 + 출력 개수)인 분포에서 랜덤하게 샘플링하여 초기화\n",
    "          # 분산을 2/(입력 개수 + 출력 개수)로 설정하는 것은 효율적인 초기화 방법으로, 입력과 출력의 개수가 많은 경우에도 가중치가 적절한 크기로 초기화\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "# G apply : 모델 내의 각 매개변수에 함수를 적용하는 데 사용됩\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e173a-c67c-4dd4-9a7c-15e4bb891402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Adam optimizer로 학습 최적화\n",
    "LEARNING_RATE = 0.0008 # 0.001, .. 0.0006, 0.0005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf2ce2-435c-4e9d-b625-0edc851a428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습(train) 함수\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train() # 학습 모드\n",
    "    epoch_loss = 0\n",
    "\n",
    "    # 전체 학습 데이터를 확인하며\n",
    "    for i, batch in tqdm(enumerate(iterator)):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        # G trg 텐서의 크기를 BERT 모델의 기대 입력 크기에 맞게 조정 (시퀀스 길이 512로 자르기)\n",
    "        bert_max_len = tokenizer.model_max_length\n",
    "        src = src[:, :bert_max_len]\n",
    "        trg = trg[:, :bert_max_len]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 출력 단어의 마지막 인덱스(<eos>)는 제외 ?? -> eos는 디코더의 입력이 아니라 디코더의 출력\n",
    "        # 입력을 할 때는 <sos>부터 시작하도록 처리\n",
    "        # G 모델은 입력 시퀀스와 이전 부분의 목표 시퀀스를 사용하여 예측을 수행\n",
    "        output, _ = model(src, trg[:,:-1])\n",
    "\n",
    "        # output: [배치 크기, trg_len - 1, output_dim]\n",
    "        # trg: [배치 크기, trg_len]\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        # 출력 단어의 인덱스 0(<sos>)은 제외\n",
    "        trg = trg[:,1:].contiguous().view(-1)\n",
    "\n",
    "        # output: [배치 크기 * trg_len - 1, output_dim]\n",
    "        # trg: [배치 크기 * trg len - 1]\n",
    "\n",
    "        # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
    "        # @output, trg : sos x, eos o\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward() # 기울기(gradient) 계산\n",
    "\n",
    "        # 기울기(gradient) clipping 진행\n",
    "        # G 그래디언트의 전체 노름(norm)을 계산합니다. 그런 다음, 노름을 지정된 임계값으로 클리핑, 그래디언트의 크기가 제한\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        # 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 전체 손실 값 계산\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd9b00-e5e8-4926-8294-a14984e55027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가(evaluate) 함수\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval() # 평가 모드\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 전체 평가 데이터를 확인하며\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            # 출력 단어의 마지막 인덱스(<eos>)는 제외\n",
    "            # 입력을 할 때는 <sos>부터 시작하도록 처리\n",
    "            output, _ = model(src, trg[:,:-1])\n",
    "\n",
    "            # output: [배치 크기, trg_len - 1, output_dim]\n",
    "            # trg: [배치 크기, trg_len]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            # 출력 단어의 인덱스 0(<sos>)은 제외\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "\n",
    "            # output: [배치 크기 * trg_len - 1, output_dim]\n",
    "            # trg: [배치 크기 * trg len - 1]\n",
    "\n",
    "            # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            # 전체 손실 값 계산\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3213c5-743e-40c3-b8b3-0fa857fa2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0c431f-11c8-4f82-9902-059fa793d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리에 현재 할당된 메모리량을 바이트 단위로 반환\n",
    "print(torch.cuda.memory_allocated()/ 1024**2)\n",
    "print(torch.cuda.memory_cached()/ 1024**2)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82b5849-953a-4495-a53f-a19ba27e1c39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "N_EPOCHS = 10 # 40, 20\n",
    "CLIP = 1\n",
    "# 최솟값을 찾기 위한 초기값으로 설정\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time() # 시작 시간 기록\n",
    "\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    # valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    valid_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "    end_time = time.time() # 종료 시간 기록\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    # valid_loss가 더 감소한 경우에만 모델 파라미터를 새로운 파일로 기록\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'transformer_german_to_english.pt')\n",
    "\n",
    "    # G epoch + 1: 현재 에포크 번호에 1을 더한 값, 2자리로 출력하고, 필요한 경우 앞에 0을 채움\n",
    "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n",
    "    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c714816c-aab7-4e46-8e47-0023a08a0886",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('transformer_german_to_english.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f9f07b-a4bf-4b2d-9f93-a827713092e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역(translation) 함수\n",
    "# 1. 하나의 sentence가 들어왔을 때\n",
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50, logging=True): # max_len - change\n",
    "    model.eval() # 평가 모드\n",
    "\n",
    "    # 토큰화\n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('fr_core_news_sm')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else: # G  문자열이 아닌 경우 이미 토큰화된 문장을 가정하고 각 토큰을 소문자로 변환\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # 처음에 <sos> 토큰, 마지막에 <eos> 토큰 붙이기\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "    if logging:\n",
    "        print(f\"전체 소스 토큰: {tokens}\")\n",
    "\n",
    "    # 모델의 입력으로 넣기 위해 각 단어를 인덱스로 바꿈\n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    if logging:\n",
    "        print(f\"소스 문장 인덱스: {src_indexes}\")\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "    # 소스 문장에 따른 마스크 생성\n",
    "    src_mask = model.make_src_mask(src_tensor)\n",
    "\n",
    "    # 인코더(endocer)에 소스 문장을 넣어 출력 값 구하기\n",
    "    with torch.no_grad():\n",
    "        enc_src = model.encoder(src_tensor, src_mask)\n",
    "\n",
    "    # 처음에는 <sos> 토큰 하나만 가지고 있도록 하기\n",
    "    # ; 실제 출력 문장은 <sos> 토큰부터 출발해서\n",
    "      # max_len까지 하나씩 반복적으로 모델의 디코더에 넣어서 출력 만듦\n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        # ?? for문 바깥 위쪽으로 빼면 안되나 -> trg_indexes와 별개로 해야함. 코드 쭉 읽어보기\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device) \n",
    "\n",
    "        # 출력 문장에 따른 마스크 생성\n",
    "        trg_mask = model.make_trg_mask(trg_tensor)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "\n",
    "        # 매번 디코더에 넣었을 때 마지막 단어가 출력 문장으로써 하나씩 추가됨\n",
    "        # 출력 문장에서 가장 마지막 단어만 사용\n",
    "        # G output에서 가장 높은 확률을 가지는 토큰의 인덱스를 추출\n",
    "          # 2 : 텐서의 차원(axis) 2를 따라 가장 큰 값을 갖는 인덱스를 반환\n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        trg_indexes.append(pred_token) # 출력 문장에 더하기\n",
    "\n",
    "        # <eos>를 만나는 순간 끝 -> 이때까지 출력된 모든 단어들이 전체 출력 문장이 됨\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "\n",
    "    # 각 출력 단어 인덱스를 실제 단어(문자열)로 변환\n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "\n",
    "    # 첫 번째 <sos>는 제외하고 출력 문장 반환\n",
    "    return trg_tokens[1:], attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb2fe97-87d7-4792-811e-c85256b6735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_idx = 10\n",
    "\n",
    "# G vars: 객체의 속성을 사전 형태로 반환하는 파이썬 내장 함수\n",
    "src = vars(test_data.examples[example_idx])['src']\n",
    "trg = vars(test_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'소스 문장: {src}')\n",
    "print(f'타겟 문장: {trg}')\n",
    "\n",
    "# attention : 8개 헤드로 구성된 어센션 스코어들의 집합\n",
    "translation, attention = translate_sentence(src, german, english, model, device, logging=True)\n",
    "\n",
    "print(\"모델 출력 결과:\", \" \".join(translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120fa4a-3b97-4b93-b043-f76da9cf5bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker # G 눈금\n",
    "\n",
    "# 각 헤드에 대한 어텐션 스코어 값 출력\n",
    "def display_attention(sentence, translation, attention, n_heads=6, n_rows=3, n_cols=2):\n",
    "\n",
    "    assert n_rows * n_cols == n_heads\n",
    "\n",
    "    # 출력할 그림 크기 조절\n",
    "    fig = plt.figure(figsize=(15, 25))\n",
    "\n",
    "    for i in range(n_heads):\n",
    "        ax = fig.add_subplot(n_rows, n_cols, i + 1)\n",
    "\n",
    "        # 어텐션(Attention) 스코어 확률 값을 이용해 그리기\n",
    "        # G 배치 차원을 제거\n",
    "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
    "\n",
    "        # G _attention 배열을 매트릭스 형태로 표시\n",
    "        # G cmap='bone'은 컬러맵을 지정하는 매개변수로, 'bone'은 흑백으로 표시\n",
    "        cax = ax.matshow(_attention, cmap='bone')\n",
    "\n",
    "        # 눈금 레이블의 크기를 12로 설정\n",
    "        ax.tick_params(labelsize=12)\n",
    "        ax.set_xticklabels([''] + ['<sos>'] + [t.lower() for t in sentence] + ['<eos>'], rotation=45)\n",
    "        ax.set_yticklabels([''] + translation)\n",
    "\n",
    "        #  x축의 눈금 간격을 설정\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.savefig('Attention_Map.png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d757a10-c12f-483b-b4ac-bbab420f0282",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_idx = 10\n",
    "\n",
    "src = vars(test_data.examples[example_idx])['src']\n",
    "trg = vars(test_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'소스 문장: {src}')\n",
    "print(f'타겟 문장: {trg}')\n",
    "\n",
    "translation, attention = translate_sentence(src, german, english, model, device, logging=True)\n",
    "\n",
    "print(\"모델 출력 결과:\", \" \".join(translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1c3e0-6556-436d-8f74-827a503617c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_attention(src, translation, attention)\n",
    "# mother를 출력하기 위해 mutter를 참고했다는 것을 시각적으로 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c6499-426d-41fe-b8c6-bf596f23bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def show_bleu(data, src_field, trg_field, model, device, max_len=100):\n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    index = 0\n",
    "\n",
    "    for datum in data:\n",
    "        # G 데이터를 사전 형태로 변환한 후, 'src' 키를 사용하여 해당 데이터의 소스 문장을 추출\n",
    "        src = vars(datum)['src']\n",
    "        trg = vars(datum)['trg']\n",
    "\n",
    "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len, logging=False)\n",
    "\n",
    "        # 마지막 <eos> 토큰 제거\n",
    "        pred_trg = pred_trg[:-1]\n",
    "\n",
    "        pred_trgs.append(pred_trg)\n",
    "        trgs.append([trg])\n",
    "\n",
    "        index += 1\n",
    "        if (index + 1) % 500 == 0:\n",
    "            print(f\"[{index + 1}/{len(data)}]\")\n",
    "            print(f\"예측: {pred_trg}\")\n",
    "            print(f\"정답: {trg}\")\n",
    "\n",
    "    # G 아래는 디폴트값과 일치 \n",
    "      # max_n : 사용할 최대 n-gram 크기를 지정\n",
    "      # eights : 각 n-gram에 대한 가중치를 지정\n",
    "    bleu = bleu_score(pred_trgs, trgs, max_n=4, weights=[0.25, 0.25, 0.25, 0.25])\n",
    "    print(f'Total BLEU Score = {bleu*100:.2f}')\n",
    "\n",
    "    # individual_bleu1_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1, 0, 0, 0])\n",
    "    # individual_bleu2_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[0, 1, 0, 0])\n",
    "    # individual_bleu3_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[0, 0, 1, 0])\n",
    "    # individual_bleu4_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[0, 0, 0, 1])\n",
    "\n",
    "    # print(f'Individual BLEU1 score = {individual_bleu1_score*100:.2f}')\n",
    "    # print(f'Individual BLEU2 score = {individual_bleu2_score*100:.2f}')\n",
    "    # print(f'Individual BLEU3 score = {individual_bleu3_score*100:.2f}')\n",
    "    # print(f'Individual BLEU4 score = {individual_bleu4_score*100:.2f}')\n",
    "\n",
    "    # # G 각 n-gram에 대한 가중치를 모두 동일하게 설정하는 대신에 ㅁ-gram까지의 n-gram을 고려\n",
    "    #   # cf) BLEU: 더 긴 n-gram에 대해서는 더 높은 가중치를 부여\n",
    "    # cumulative_bleu1_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1, 0, 0, 0])\n",
    "    # cumulative_bleu2_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1/2, 1/2, 0, 0])\n",
    "    # cumulative_bleu3_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1/3, 1/3, 1/3, 0])\n",
    "    # cumulative_bleu4_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1/4, 1/4, 1/4, 1/4])\n",
    "\n",
    "    # print(f'Cumulative BLEU1 score = {cumulative_bleu1_score*100:.2f}')\n",
    "    # print(f'Cumulative BLEU2 score = {cumulative_bleu2_score*100:.2f}')\n",
    "    # print(f'Cumulative BLEU3 score = {cumulative_bleu3_score*100:.2f}')\n",
    "    # print(f'Cumulative BLEU4 score = {cumulative_bleu4_score*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1591c701-cfcb-447c-86ec-7fc6fad8206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bleu(test_data, german, english, model, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
